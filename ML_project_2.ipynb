{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q9Ai4PMWLp89"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "# ! pip install sentence_transformers\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "import random\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "from torch.utils.data.sampler import WeightedRandomSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data"
      ],
      "metadata": {
        "id": "NJDk1CEaNVOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/data_processed.csv\")\n",
        "data['class'] = data['class'].replace(0, 1)\n",
        "data['class'] = data['class']-1\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LFjRWQYENWvq",
        "outputId": "48ad4b96-8418-4a50-d20d-f9ec5f4e447a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0               0      3            0                   0        3      1   \n",
              "1               1      3            0                   3        0      0   \n",
              "2               2      3            0                   3        0      0   \n",
              "3               3      3            0                   2        1      0   \n",
              "4               4      6            0                   6        0      0   \n",
              "...           ...    ...          ...                 ...      ...    ...   \n",
              "24768       25291      3            0                   2        1      0   \n",
              "24769       25292      3            0                   1        2      1   \n",
              "24770       25294      3            0                   3        0      0   \n",
              "24771       25295      6            0                   6        0      0   \n",
              "24772       25296      3            0                   0        3      1   \n",
              "\n",
              "                                                   tweet  \n",
              "0       as a woman you shouldnt complain about cleani...  \n",
              "1       boy dats coldtyga dwn bad for cuffin dat hoe ...  \n",
              "2       dawg you ever fuck a bitch and she start to c...  \n",
              "3                                 she look like a tranny  \n",
              "4       the shit you hear about me might be true or i...  \n",
              "...                                                  ...  \n",
              "24768  yous a muthafin lie right his tl is trash now ...  \n",
              "24769  youve gone and broke the wrong heart baby and ...  \n",
              "24770  young buck wanna eat dat nigguh like i aint fu...  \n",
              "24771              youu got wild bitches tellin you lies  \n",
              "24772  ruffled ntac eileen dahlia beautiful color com...  \n",
              "\n",
              "[24773 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f1b4f74-4c4a-43e8-9ed5-e89d818bac82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>as a woman you shouldnt complain about cleani...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>boy dats coldtyga dwn bad for cuffin dat hoe ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>dawg you ever fuck a bitch and she start to c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>she look like a tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>the shit you hear about me might be true or i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24768</th>\n",
              "      <td>25291</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>yous a muthafin lie right his tl is trash now ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24769</th>\n",
              "      <td>25292</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>youve gone and broke the wrong heart baby and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24770</th>\n",
              "      <td>25294</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>young buck wanna eat dat nigguh like i aint fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24771</th>\n",
              "      <td>25295</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24772</th>\n",
              "      <td>25296</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>ruffled ntac eileen dahlia beautiful color com...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24773 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f1b4f74-4c4a-43e8-9ed5-e89d818bac82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f1b4f74-4c4a-43e8-9ed5-e89d818bac82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f1b4f74-4c4a-43e8-9ed5-e89d818bac82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "sentences = data[\"tweet\"]\n",
        "# sentence_embeddings = model.encode(sentences)\n",
        "words = [list(s.lower().split()) for s in sentences]"
      ],
      "metadata": {
        "id": "geG6DIsqRe8r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = Word2Vec(sentences=words, size=384, window=5, min_count=1, workers=4)\n",
        "\n",
        "# import gensim.downloader as api\n",
        "# corpus = api.load('text8')  # download the corpus and return it opened as an iterable\n",
        "# w2v = Word2Vec(corpus)\n",
        "# w2v.train(sentences=words)\n",
        "\n",
        "sentence_embeddings = [torch.as_tensor([w2v.wv[word] for word in list(s.lower().split())]) for s in sentences]"
      ],
      "metadata": {
        "id": "PwSOGtPz11Og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47365a6b-b667-41b1-81e3-220678614b71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-2433b6dc6a7e>:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  sentence_embeddings = [torch.as_tensor([w2v.wv[word] for word in list(s.lower().split())]) for s in sentences]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = np.array(data[\"class\"])\n",
        "assert len(label) == len(sentence_embeddings)"
      ],
      "metadata": {
        "id": "ki3pRLAeT24w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-validation-test split"
      ],
      "metadata": {
        "id": "mvbeeSpdUtwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_rem, y_train, y_rem = train_test_split(sentence_embeddings,label, train_size=0.7,stratify=label, balan)\n",
        "# X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
      ],
      "metadata": {
        "id": "CWB8uMW9UJSg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_and_test_set_balanced(X, y, train_ratio=0.75):\n",
        "    # TODO\n",
        "    # process the list of (x,y) pairs and split them 80-20 into train and test set\n",
        "    # train_x is a list of name embeddings each of size (num_characters_in_name, 1, n_letters), train_y is the corresponding list of language category index. Same for test_x and test_y\n",
        "\n",
        "    X, X_rem, y, y_rem = X[0:int(train_ratio * len(X))], X[int(train_ratio * len(X)) + 1:-1], y[0:int(train_ratio * len(y))], y[int(train_ratio * len(y)) + 1:-1]\n",
        "    counts = np.bincount(y)\n",
        "    label_weights = 1.0 / counts\n",
        "    weights = label_weights[y]\n",
        "    index = list(WeightedRandomSampler(weights, len(weights)))\n",
        "    X_train, y_train = [X[i] for i in index], [y[i] for i in index]\n",
        "\n",
        "    return X_train, X_rem, y_train, y_rem"
      ],
      "metadata": {
        "id": "3wZ1REB0IerP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_rem, y_train, y_rem = create_train_and_test_set_balanced(sentence_embeddings,label)\n",
        "X_valid, X_test, y_valid, y_test = create_train_and_test_set_balanced(X_rem,y_rem)"
      ],
      "metadata": {
        "id": "fhyriPodI4HT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class Tweet(Dataset):\n",
        "    def __init__(self, X,y, transform=None):\n",
        "        self.X = pad_sequence(X,batch_first=True)\n",
        "        self.y = torch.as_tensor(np.array(y))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.X[idx]\n",
        "        label = self.y[idx]\n",
        "        sample = {'sentence': sentence, 'label': label}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "QSbvmwrcf8wF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model"
      ],
      "metadata": {
        "id": "v8jbV7gZWIGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "output_size = 2\n",
        "batch_size = 50\n",
        "\n",
        "valid_losses = []"
      ],
      "metadata": {
        "id": "dOpX0gRfEvoz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Tweet(X_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0,drop_last=True)\n",
        "\n",
        "valid_data = Tweet(X_valid, y_valid)\n",
        "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=0,drop_last=True)\n",
        "\n",
        "test_data = Tweet(X_test, y_test)\n",
        "test_loader = DataLoader(test_data, batch_size=len(X_test), shuffle=True, num_workers=0,drop_last=True)"
      ],
      "metadata": {
        "id": "iS5akB3pE_sO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class lstm(nn.Module):\n",
        "    def __init__(self, embedding_length=384,dropout = 0.2):\n",
        "        super(lstm, self).__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.batch_size = batch_size\n",
        "        self.fc1 = nn.Linear(embedding_length, 256)\n",
        "        self.lstm = nn.LSTM(embedding_length, self.hidden_size,batch_first=True,dropout=0.2, num_layers=1)\n",
        "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size//2)\n",
        "        self.label = nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.to(\"cuda\")\n",
        "\n",
        "\n",
        "    def forward(self,input):\n",
        "\n",
        "        input = input.to(\"cuda\")\n",
        "\n",
        "        # input = self.fc1(input)\n",
        "        # input = self.relu(input)\n",
        "\n",
        "        h_0 = Variable(torch.zeros(1, len(input), self.hidden_size).cuda())\n",
        "        c_0 = Variable(torch.zeros(1, len(input), self.hidden_size).cuda())\n",
        "\n",
        "\n",
        "        output, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0))\n",
        "        # x = self.fc2(final_hidden_state[-1])\n",
        "        # x = self.relu(x)\n",
        "\n",
        "        return self.label(final_hidden_state[-1])\n",
        "    \n",
        "\n",
        "    def fit(self, train_loader, epochs=100,lr=1e-5,interval=100):\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            running_loss = 0.0\n",
        "            self.train()\n",
        "\n",
        "            for i_batch, sample in enumerate(train_loader):\n",
        "                sentences, labels = sample['sentence'].to(\"cuda\"), sample['label'].to(\"cuda\")\n",
        "\n",
        "                outputs = self(sentences)\n",
        "                loss = criterion(\n",
        "                    outputs,\n",
        "                    labels,\n",
        "                )\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                if i_batch % interval == 0 and i_batch > 0:\n",
        "                    valid_loss = self.validate(valid_loader=valid_loader)\n",
        "                    print(f\"epoch:{epoch},batch: {i_batch}, train_loss: {running_loss/interval}, valid_loss: {valid_loss}\")\n",
        "                    running_loss = 0\n",
        "            valid_losses.append([epoch,self.validate(valid_loader)])\n",
        "\n",
        "    def validate(self, valid_loader):\n",
        "        running_loss = 0\n",
        "        val_count = 0\n",
        "        # self.eval()\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        for i_batch, sample in enumerate(valid_loader):\n",
        "            sentences, labels = sample['sentence'].to(\"cuda\"), sample['label'].to(\"cuda\")\n",
        "\n",
        "            outputs = self(sentences)\n",
        "            loss = criterion(\n",
        "                outputs,\n",
        "                labels,\n",
        "            )\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            val_count += 1\n",
        "\n",
        "        avg_loss = running_loss / val_count\n",
        "        return avg_loss\n",
        "\n",
        "    def accuracy(self,test_loader):\n",
        "        self.eval()\n",
        "        for i_batch, sample in enumerate(test_loader):\n",
        "            sentences, labels = sample['sentence'], sample['label']\n",
        "    \n",
        "            outputs = self(sentences)\n",
        "            pred = np.array([np.argmax(outputs[i].cpu().detach().numpy()) for i in range(len(outputs))])\n",
        "            assert len(pred) == len(labels)\n",
        "\n",
        "            return np.sum(labels.numpy() == pred) / len(pred)\n",
        "\n",
        "\n",
        "    def predict(self,sentence):\n",
        "        vec = torch.as_tensor([w2v.wv[word] for word in list(sentence.lower().split())])\n",
        "        vec = vec.unsqueeze(0)\n",
        "        index =  np.argmax(self(vec).cpu().detach().numpy()) \n",
        "\n",
        "        # label_to_senti = {0:\"hate speech\",1:\"offensive language\",2:\"neither\"}\n",
        "        label_to_senti = {0:\"offensive\",1:\"normal\"}\n",
        "        return label_to_senti[index]"
      ],
      "metadata": {
        "id": "Bp-5MBCQVPw5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = lstm()\n",
        "valid_losses = []\n",
        "lstm_model.fit(train_loader=train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlNCSyJEatXa",
        "outputId": "950796dd-378b-413d-9bc9-8cfdb6041dc0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0,batch: 100, train_loss: 0.7001983493566513, valid_loss: 0.6931327749853549\n",
            "epoch:0,batch: 200, train_loss: 0.6932268583774567, valid_loss: 0.6929790831130483\n",
            "epoch:0,batch: 300, train_loss: 0.6929517024755478, valid_loss: 0.6928897934115451\n",
            "epoch:1,batch: 100, train_loss: 0.7000130397081376, valid_loss: 0.6927365032227143\n",
            "epoch:1,batch: 200, train_loss: 0.6930716466903687, valid_loss: 0.6925794099983962\n",
            "epoch:1,batch: 300, train_loss: 0.6929628670215606, valid_loss: 0.6925095663122509\n",
            "epoch:2,batch: 100, train_loss: 0.6998315644264221, valid_loss: 0.6922530862300292\n",
            "epoch:2,batch: 200, train_loss: 0.6929259419441223, valid_loss: 0.6921076554319133\n",
            "epoch:2,batch: 300, train_loss: 0.6928817850351333, valid_loss: 0.6919728608235068\n",
            "epoch:3,batch: 100, train_loss: 0.6997095501422882, valid_loss: 0.691582009844158\n",
            "epoch:3,batch: 200, train_loss: 0.6925119584798813, valid_loss: 0.6911364780819934\n",
            "epoch:3,batch: 300, train_loss: 0.6925213080644608, valid_loss: 0.6907897293567657\n",
            "epoch:4,batch: 100, train_loss: 0.6988389676809311, valid_loss: 0.6900524710831435\n",
            "epoch:4,batch: 200, train_loss: 0.6920520317554474, valid_loss: 0.6895254999399185\n",
            "epoch:4,batch: 300, train_loss: 0.691554878950119, valid_loss: 0.6889059485300727\n",
            "epoch:5,batch: 100, train_loss: 0.6974839228391647, valid_loss: 0.6871752253045207\n",
            "epoch:5,batch: 200, train_loss: 0.6894655990600586, valid_loss: 0.6853899709556414\n",
            "epoch:5,batch: 300, train_loss: 0.6876387709379196, valid_loss: 0.6815829873085022\n",
            "epoch:6,batch: 100, train_loss: 0.6866625851392746, valid_loss: 0.6743640472059664\n",
            "epoch:6,batch: 200, train_loss: 0.6792802250385285, valid_loss: 0.6728173073219217\n",
            "epoch:6,batch: 300, train_loss: 0.6718625915050507, valid_loss: 0.6626441271408744\n",
            "epoch:7,batch: 100, train_loss: 0.6491264325380325, valid_loss: 0.6241412486719049\n",
            "epoch:7,batch: 200, train_loss: 0.6312851029634475, valid_loss: 0.6016615188640096\n",
            "epoch:7,batch: 300, train_loss: 0.5993096369504929, valid_loss: 0.5811992077075917\n",
            "epoch:8,batch: 100, train_loss: 0.5667190772294998, valid_loss: 0.5479357064418171\n",
            "epoch:8,batch: 200, train_loss: 0.5446021768450737, valid_loss: 0.5372322959744412\n",
            "epoch:8,batch: 300, train_loss: 0.5326703369617463, valid_loss: 0.5139457858774973\n",
            "epoch:9,batch: 100, train_loss: 0.5116140857338906, valid_loss: 0.49404023101796274\n",
            "epoch:9,batch: 200, train_loss: 0.49498154073953626, valid_loss: 0.49025262147188187\n",
            "epoch:9,batch: 300, train_loss: 0.4866899627447128, valid_loss: 0.4836937357550082\n",
            "epoch:10,batch: 100, train_loss: 0.4735425263643265, valid_loss: 0.46006880700588226\n",
            "epoch:10,batch: 200, train_loss: 0.4649581241607666, valid_loss: 0.4518713212531546\n",
            "epoch:10,batch: 300, train_loss: 0.4538553470373154, valid_loss: 0.4450429402615713\n",
            "epoch:11,batch: 100, train_loss: 0.4470580270886421, valid_loss: 0.4372401383260022\n",
            "epoch:11,batch: 200, train_loss: 0.4465754869580269, valid_loss: 0.425419805166514\n",
            "epoch:11,batch: 300, train_loss: 0.42647412240505217, valid_loss: 0.41916044315566187\n",
            "epoch:12,batch: 100, train_loss: 0.4242019316554069, valid_loss: 0.4070811329976372\n",
            "epoch:12,batch: 200, train_loss: 0.40215877145528794, valid_loss: 0.4088893233110075\n",
            "epoch:12,batch: 300, train_loss: 0.4115725091099739, valid_loss: 0.39650816859110544\n",
            "epoch:13,batch: 100, train_loss: 0.3996331287920475, valid_loss: 0.4021157116993614\n",
            "epoch:13,batch: 200, train_loss: 0.40089616775512693, valid_loss: 0.38168685818495957\n",
            "epoch:13,batch: 300, train_loss: 0.37757570028305054, valid_loss: 0.3774274548758631\n",
            "epoch:14,batch: 100, train_loss: 0.3885698583722115, valid_loss: 0.37887870034445886\n",
            "epoch:14,batch: 200, train_loss: 0.38263903647661207, valid_loss: 0.3681603576178136\n",
            "epoch:14,batch: 300, train_loss: 0.36526519149541853, valid_loss: 0.3714863651472589\n",
            "epoch:15,batch: 100, train_loss: 0.3682060432434082, valid_loss: 0.36637896639497386\n",
            "epoch:15,batch: 200, train_loss: 0.3607989513874054, valid_loss: 0.3518251117480838\n",
            "epoch:15,batch: 300, train_loss: 0.36349839448928833, valid_loss: 0.35272452947886096\n",
            "epoch:16,batch: 100, train_loss: 0.3567550317943096, valid_loss: 0.3499211774248144\n",
            "epoch:16,batch: 200, train_loss: 0.3472437036037445, valid_loss: 0.3438219473413799\n",
            "epoch:16,batch: 300, train_loss: 0.3573537804186344, valid_loss: 0.345325851570005\n",
            "epoch:17,batch: 100, train_loss: 0.3443775464594364, valid_loss: 0.3344161005123802\n",
            "epoch:17,batch: 200, train_loss: 0.3550160652399063, valid_loss: 0.33459823643383774\n",
            "epoch:17,batch: 300, train_loss: 0.33852578297257424, valid_loss: 0.332361523385929\n",
            "epoch:18,batch: 100, train_loss: 0.3501471908390522, valid_loss: 0.3320338193165219\n",
            "epoch:18,batch: 200, train_loss: 0.3249424107372761, valid_loss: 0.3236603157027908\n",
            "epoch:18,batch: 300, train_loss: 0.3287786105275154, valid_loss: 0.32813651973138686\n",
            "epoch:19,batch: 100, train_loss: 0.3353487966954708, valid_loss: 0.3327523239928743\n",
            "epoch:19,batch: 200, train_loss: 0.33516384676098826, valid_loss: 0.318478439975044\n",
            "epoch:19,batch: 300, train_loss: 0.3167069779336453, valid_loss: 0.3152901123723258\n",
            "epoch:20,batch: 100, train_loss: 0.3254013246297836, valid_loss: 0.32141760347977927\n",
            "epoch:20,batch: 200, train_loss: 0.33115660727024077, valid_loss: 0.31444689469492954\n",
            "epoch:20,batch: 300, train_loss: 0.3100091218948364, valid_loss: 0.31849592713558156\n",
            "epoch:21,batch: 100, train_loss: 0.32101704373955725, valid_loss: 0.3330996208216833\n",
            "epoch:21,batch: 200, train_loss: 0.31588794648647306, valid_loss: 0.3081393073434415\n",
            "epoch:21,batch: 300, train_loss: 0.3167474390566349, valid_loss: 0.33398767058616097\n",
            "epoch:22,batch: 100, train_loss: 0.3171082226932049, valid_loss: 0.3060440361175848\n",
            "epoch:22,batch: 200, train_loss: 0.3123610931634903, valid_loss: 0.3084747768614603\n",
            "epoch:22,batch: 300, train_loss: 0.31055974766612054, valid_loss: 0.33562300435226894\n",
            "epoch:23,batch: 100, train_loss: 0.3166733151674271, valid_loss: 0.30110814098430716\n",
            "epoch:23,batch: 200, train_loss: 0.3164415420591831, valid_loss: 0.30788891406162927\n",
            "epoch:23,batch: 300, train_loss: 0.3032036390900612, valid_loss: 0.29904041641756246\n",
            "epoch:24,batch: 100, train_loss: 0.3065990650653839, valid_loss: 0.2983842989348847\n",
            "epoch:24,batch: 200, train_loss: 0.2992742794752121, valid_loss: 0.3142927817028502\n",
            "epoch:24,batch: 300, train_loss: 0.3066010797023773, valid_loss: 0.3014430779477824\n",
            "epoch:25,batch: 100, train_loss: 0.3025212118774652, valid_loss: 0.29828012426910194\n",
            "epoch:25,batch: 200, train_loss: 0.3056126552820206, valid_loss: 0.3242602980007296\n",
            "epoch:25,batch: 300, train_loss: 0.3094710972905159, valid_loss: 0.31415558687370754\n",
            "epoch:26,batch: 100, train_loss: 0.31152114614844323, valid_loss: 0.2960360526390698\n",
            "epoch:26,batch: 200, train_loss: 0.3024842663109302, valid_loss: 0.30299498383765633\n",
            "epoch:26,batch: 300, train_loss: 0.2997619643807411, valid_loss: 0.30161520174663997\n",
            "epoch:27,batch: 100, train_loss: 0.30164608508348467, valid_loss: 0.30234104840327863\n",
            "epoch:27,batch: 200, train_loss: 0.300460873991251, valid_loss: 0.30584470862927643\n",
            "epoch:27,batch: 300, train_loss: 0.30282955795526506, valid_loss: 0.31852158952666365\n",
            "epoch:28,batch: 100, train_loss: 0.3076267173886299, valid_loss: 0.2915759109284567\n",
            "epoch:28,batch: 200, train_loss: 0.30116962164640426, valid_loss: 0.2931315772559332\n",
            "epoch:28,batch: 300, train_loss: 0.28392147421836855, valid_loss: 0.2907384894788265\n",
            "epoch:29,batch: 100, train_loss: 0.29974296763539315, valid_loss: 0.30178403287478117\n",
            "epoch:29,batch: 200, train_loss: 0.3021797855198383, valid_loss: 0.3052634924002316\n",
            "epoch:29,batch: 300, train_loss: 0.3044400416314602, valid_loss: 0.31629208442957507\n",
            "epoch:30,batch: 100, train_loss: 0.2862505171447992, valid_loss: 0.297075593115195\n",
            "epoch:30,batch: 200, train_loss: 0.29983412981033325, valid_loss: 0.31533417640172917\n",
            "epoch:30,batch: 300, train_loss: 0.30731179475784304, valid_loss: 0.2942192164128241\n",
            "epoch:31,batch: 100, train_loss: 0.29855276212096216, valid_loss: 0.2858477069631867\n",
            "epoch:31,batch: 200, train_loss: 0.30518927186727524, valid_loss: 0.2952611704721399\n",
            "epoch:31,batch: 300, train_loss: 0.28675551667809485, valid_loss: 0.2950814826333005\n",
            "epoch:32,batch: 100, train_loss: 0.3071631081402302, valid_loss: 0.3276526432322419\n",
            "epoch:32,batch: 200, train_loss: 0.2770287829637528, valid_loss: 0.30213263063975004\n",
            "epoch:32,batch: 300, train_loss: 0.3014895785599947, valid_loss: 0.2838180111316235\n",
            "epoch:33,batch: 100, train_loss: 0.3026522183418274, valid_loss: 0.28360789828002453\n",
            "epoch:33,batch: 200, train_loss: 0.30192602120339873, valid_loss: 0.2906932234764099\n",
            "epoch:33,batch: 300, train_loss: 0.2890223990380764, valid_loss: 0.294617905402961\n",
            "epoch:34,batch: 100, train_loss: 0.2939144268631935, valid_loss: 0.28238303141425486\n",
            "epoch:34,batch: 200, train_loss: 0.2923589845746756, valid_loss: 0.2880586792269479\n",
            "epoch:34,batch: 300, train_loss: 0.29369984842836855, valid_loss: 0.3001431900521983\n",
            "epoch:35,batch: 100, train_loss: 0.30169351935386657, valid_loss: 0.28748325744400854\n",
            "epoch:35,batch: 200, train_loss: 0.27837598621845244, valid_loss: 0.2958054226701674\n",
            "epoch:35,batch: 300, train_loss: 0.2869486541301012, valid_loss: 0.3282190405804178\n",
            "epoch:36,batch: 100, train_loss: 0.29299223341047764, valid_loss: 0.2887298489880303\n",
            "epoch:36,batch: 200, train_loss: 0.2898566311597824, valid_loss: 0.2941681140142938\n",
            "epoch:36,batch: 300, train_loss: 0.2908835351467133, valid_loss: 0.28550665501667105\n",
            "epoch:37,batch: 100, train_loss: 0.2876676639914513, valid_loss: 0.29760324258519255\n",
            "epoch:37,batch: 200, train_loss: 0.288104365170002, valid_loss: 0.2870905990509883\n",
            "epoch:37,batch: 300, train_loss: 0.29031109899282453, valid_loss: 0.294172245523204\n",
            "epoch:38,batch: 100, train_loss: 0.28776734687387945, valid_loss: 0.28036573958461697\n",
            "epoch:38,batch: 200, train_loss: 0.2939304620027542, valid_loss: 0.2800499846267959\n",
            "epoch:38,batch: 300, train_loss: 0.28386808693408966, valid_loss: 0.28030426460115804\n",
            "epoch:39,batch: 100, train_loss: 0.30383212327957154, valid_loss: 0.3122277818620205\n",
            "epoch:39,batch: 200, train_loss: 0.2949188183248043, valid_loss: 0.2840785602836505\n",
            "epoch:39,batch: 300, train_loss: 0.2734696950763464, valid_loss: 0.2833029128935026\n",
            "epoch:40,batch: 100, train_loss: 0.29623734779655936, valid_loss: 0.28750526095214096\n",
            "epoch:40,batch: 200, train_loss: 0.29492270804941656, valid_loss: 0.3136639002224673\n",
            "epoch:40,batch: 300, train_loss: 0.270479059740901, valid_loss: 0.2890469040721655\n",
            "epoch:41,batch: 100, train_loss: 0.30222759790718556, valid_loss: 0.29103898208426393\n",
            "epoch:41,batch: 200, train_loss: 0.28366367764770983, valid_loss: 0.2754141899716595\n",
            "epoch:41,batch: 300, train_loss: 0.2906313174962997, valid_loss: 0.284964513114613\n",
            "epoch:42,batch: 100, train_loss: 0.2991954480111599, valid_loss: 0.2911589131893023\n",
            "epoch:42,batch: 200, train_loss: 0.28451614052057267, valid_loss: 0.2758119532271572\n",
            "epoch:42,batch: 300, train_loss: 0.2857404860854149, valid_loss: 0.30477782233577705\n",
            "epoch:43,batch: 100, train_loss: 0.3018140944838524, valid_loss: 0.27897333459037804\n",
            "epoch:43,batch: 200, train_loss: 0.28122758261859415, valid_loss: 0.28052467545089516\n",
            "epoch:43,batch: 300, train_loss: 0.28680864691734315, valid_loss: 0.2779237702488899\n",
            "epoch:44,batch: 100, train_loss: 0.281698477268219, valid_loss: 0.32784512817211775\n",
            "epoch:44,batch: 200, train_loss: 0.291147830337286, valid_loss: 0.2780705459577882\n",
            "epoch:44,batch: 300, train_loss: 0.29610743425786495, valid_loss: 0.27541366454375826\n",
            "epoch:45,batch: 100, train_loss: 0.2859683528542519, valid_loss: 0.2744530198042807\n",
            "epoch:45,batch: 200, train_loss: 0.2720080903172493, valid_loss: 0.2810867209311413\n",
            "epoch:45,batch: 300, train_loss: 0.2926973343640566, valid_loss: 0.28344231447123963\n",
            "epoch:46,batch: 100, train_loss: 0.28300488367676735, valid_loss: 0.28344549773179967\n",
            "epoch:46,batch: 200, train_loss: 0.29179037183523177, valid_loss: 0.2719469308529211\n",
            "epoch:46,batch: 300, train_loss: 0.2823993856459856, valid_loss: 0.2739026241166436\n",
            "epoch:47,batch: 100, train_loss: 0.2899824123084545, valid_loss: 0.2754248324781656\n",
            "epoch:47,batch: 200, train_loss: 0.28301030382514, valid_loss: 0.2746864414733389\n",
            "epoch:47,batch: 300, train_loss: 0.286412997096777, valid_loss: 0.29210779265217157\n",
            "epoch:48,batch: 100, train_loss: 0.28066987976431845, valid_loss: 0.28589502430480457\n",
            "epoch:48,batch: 200, train_loss: 0.27946634493768213, valid_loss: 0.308619297069052\n",
            "epoch:48,batch: 300, train_loss: 0.2885440228134394, valid_loss: 0.27795432184053503\n",
            "epoch:49,batch: 100, train_loss: 0.2873268549144268, valid_loss: 0.2739606951565846\n",
            "epoch:49,batch: 200, train_loss: 0.2836172479391098, valid_loss: 0.2761442478260268\n",
            "epoch:49,batch: 300, train_loss: 0.2819564583897591, valid_loss: 0.2889262535001921\n",
            "epoch:50,batch: 100, train_loss: 0.2897334115952253, valid_loss: 0.27987560062952666\n",
            "epoch:50,batch: 200, train_loss: 0.2752531869709492, valid_loss: 0.27595788450992625\n",
            "epoch:50,batch: 300, train_loss: 0.2803226487338543, valid_loss: 0.2712496209727681\n",
            "epoch:51,batch: 100, train_loss: 0.2853696079552174, valid_loss: 0.2887710443009501\n",
            "epoch:51,batch: 200, train_loss: 0.2793320757895708, valid_loss: 0.27244318390022154\n",
            "epoch:51,batch: 300, train_loss: 0.27483638241887093, valid_loss: 0.2862039993962516\n",
            "epoch:52,batch: 100, train_loss: 0.29305786699056624, valid_loss: 0.2954457145508217\n",
            "epoch:52,batch: 200, train_loss: 0.2813964629173279, valid_loss: 0.2738863484043142\n",
            "epoch:52,batch: 300, train_loss: 0.2794756151735783, valid_loss: 0.27152461574777315\n",
            "epoch:53,batch: 100, train_loss: 0.28147264689207074, valid_loss: 0.2694824070710203\n",
            "epoch:53,batch: 200, train_loss: 0.28362539522349833, valid_loss: 0.278639480471611\n",
            "epoch:53,batch: 300, train_loss: 0.2804031852632761, valid_loss: 0.27163574366789794\n",
            "epoch:54,batch: 100, train_loss: 0.2734613011777401, valid_loss: 0.2985500528112702\n",
            "epoch:54,batch: 200, train_loss: 0.28461857929825785, valid_loss: 0.3020984826852446\n",
            "epoch:54,batch: 300, train_loss: 0.2822740405797958, valid_loss: 0.27070079290348553\n",
            "epoch:55,batch: 100, train_loss: 0.28298682153224947, valid_loss: 0.2670252528041601\n",
            "epoch:55,batch: 200, train_loss: 0.28296902634203436, valid_loss: 0.28356081295920454\n",
            "epoch:55,batch: 300, train_loss: 0.27854029536247255, valid_loss: 0.27240745366915414\n",
            "epoch:56,batch: 100, train_loss: 0.27563210159540175, valid_loss: 0.271021050117586\n",
            "epoch:56,batch: 200, train_loss: 0.2711804765462875, valid_loss: 0.27242560409333394\n",
            "epoch:56,batch: 300, train_loss: 0.2850418896973133, valid_loss: 0.27235150061871694\n",
            "epoch:57,batch: 100, train_loss: 0.26760306194424627, valid_loss: 0.296677659549143\n",
            "epoch:57,batch: 200, train_loss: 0.2963572232425213, valid_loss: 0.27260764761139517\n",
            "epoch:57,batch: 300, train_loss: 0.27488654375076294, valid_loss: 0.2697244247664576\n",
            "epoch:58,batch: 100, train_loss: 0.27643711790442466, valid_loss: 0.3142518320161363\n",
            "epoch:58,batch: 200, train_loss: 0.27792253874242306, valid_loss: 0.2744866441935301\n",
            "epoch:58,batch: 300, train_loss: 0.2781539363414049, valid_loss: 0.26894580167920695\n",
            "epoch:59,batch: 100, train_loss: 0.28841883793473244, valid_loss: 0.2765144808622806\n",
            "epoch:59,batch: 200, train_loss: 0.28457037709653377, valid_loss: 0.28566811266152753\n",
            "epoch:59,batch: 300, train_loss: 0.2634184641391039, valid_loss: 0.26927481656489166\n",
            "epoch:60,batch: 100, train_loss: 0.28098238840699197, valid_loss: 0.2710847525816897\n",
            "epoch:60,batch: 200, train_loss: 0.26746905080974104, valid_loss: 0.2900032499886077\n",
            "epoch:60,batch: 300, train_loss: 0.2803481063246727, valid_loss: 0.29766676607339276\n",
            "epoch:61,batch: 100, train_loss: 0.2836361540108919, valid_loss: 0.28906239512497967\n",
            "epoch:61,batch: 200, train_loss: 0.2708343848586082, valid_loss: 0.27359109064159187\n",
            "epoch:61,batch: 300, train_loss: 0.28295095659792424, valid_loss: 0.3213975102357242\n",
            "epoch:62,batch: 100, train_loss: 0.2835390695929527, valid_loss: 0.27400015197370364\n",
            "epoch:62,batch: 200, train_loss: 0.2692148597538471, valid_loss: 0.269899246485337\n",
            "epoch:62,batch: 300, train_loss: 0.27259400859475136, valid_loss: 0.2684212335101936\n",
            "epoch:63,batch: 100, train_loss: 0.26687070846557615, valid_loss: 0.2835265738160714\n",
            "epoch:63,batch: 200, train_loss: 0.29956047840416433, valid_loss: 0.272409555380759\n",
            "epoch:63,batch: 300, train_loss: 0.2623699866235256, valid_loss: 0.2930385077615147\n",
            "epoch:64,batch: 100, train_loss: 0.2897661294788122, valid_loss: 0.26735396909972897\n",
            "epoch:64,batch: 200, train_loss: 0.2730426447838545, valid_loss: 0.2693679531955201\n",
            "epoch:64,batch: 300, train_loss: 0.2657863934338093, valid_loss: 0.2954915493078854\n",
            "epoch:65,batch: 100, train_loss: 0.2731160745024681, valid_loss: 0.2776210688702438\n",
            "epoch:65,batch: 200, train_loss: 0.2765408743172884, valid_loss: 0.28083642345407733\n",
            "epoch:65,batch: 300, train_loss: 0.27331591039896014, valid_loss: 0.2759505275474942\n",
            "epoch:66,batch: 100, train_loss: 0.28334530130028723, valid_loss: 0.2725499090941056\n",
            "epoch:66,batch: 200, train_loss: 0.2763792188465595, valid_loss: 0.26058414027742716\n",
            "epoch:66,batch: 300, train_loss: 0.26858811601996424, valid_loss: 0.2985889731865862\n",
            "epoch:67,batch: 100, train_loss: 0.26569756254553795, valid_loss: 0.28213971909945423\n",
            "epoch:67,batch: 200, train_loss: 0.27152692154049873, valid_loss: 0.2616389367081549\n",
            "epoch:67,batch: 300, train_loss: 0.2804025476425886, valid_loss: 0.273192019890184\n",
            "epoch:68,batch: 100, train_loss: 0.27684027820825574, valid_loss: 0.3024775704935841\n",
            "epoch:68,batch: 200, train_loss: 0.27404937326908113, valid_loss: 0.27018221143795096\n",
            "epoch:68,batch: 300, train_loss: 0.27958826430141925, valid_loss: 0.316097328034432\n",
            "epoch:69,batch: 100, train_loss: 0.27393050320446494, valid_loss: 0.26852518101425277\n",
            "epoch:69,batch: 200, train_loss: 0.2633634546399117, valid_loss: 0.28385877641646756\n",
            "epoch:69,batch: 300, train_loss: 0.284093411564827, valid_loss: 0.2583915680322958\n",
            "epoch:70,batch: 100, train_loss: 0.273530010804534, valid_loss: 0.27203753639174544\n",
            "epoch:70,batch: 200, train_loss: 0.2715814006328583, valid_loss: 0.2729968544419693\n",
            "epoch:70,batch: 300, train_loss: 0.27464713707566263, valid_loss: 0.29059532203752064\n",
            "epoch:71,batch: 100, train_loss: 0.27162075504660604, valid_loss: 0.2738227175305719\n",
            "epoch:71,batch: 200, train_loss: 0.26671580731868744, valid_loss: 0.26770006055417267\n",
            "epoch:71,batch: 300, train_loss: 0.2759538744390011, valid_loss: 0.2668345644665153\n",
            "epoch:72,batch: 100, train_loss: 0.28332951597869394, valid_loss: 0.25766829109710193\n",
            "epoch:72,batch: 200, train_loss: 0.25647856570780275, valid_loss: 0.27345504692715145\n",
            "epoch:72,batch: 300, train_loss: 0.2688129752874374, valid_loss: 0.2598759395920712\n",
            "epoch:73,batch: 100, train_loss: 0.280052954480052, valid_loss: 0.2853489677705195\n",
            "epoch:73,batch: 200, train_loss: 0.26273014083504675, valid_loss: 0.26033907100234344\n",
            "epoch:73,batch: 300, train_loss: 0.2666117041558027, valid_loss: 0.3093368589230206\n",
            "epoch:74,batch: 100, train_loss: 0.2776307632774115, valid_loss: 0.2693964280997929\n",
            "epoch:74,batch: 200, train_loss: 0.27294215239584446, valid_loss: 0.27443755207502324\n",
            "epoch:74,batch: 300, train_loss: 0.26804379098117354, valid_loss: 0.2926629760667034\n",
            "epoch:75,batch: 100, train_loss: 0.2731268218904734, valid_loss: 0.2754473634388136\n",
            "epoch:75,batch: 200, train_loss: 0.2584709107130766, valid_loss: 0.26342437513496564\n",
            "epoch:75,batch: 300, train_loss: 0.27967102408409117, valid_loss: 0.26521362647738145\n",
            "epoch:76,batch: 100, train_loss: 0.27653365314006806, valid_loss: 0.26052263006567955\n",
            "epoch:76,batch: 200, train_loss: 0.2704578844457865, valid_loss: 0.26336781510516355\n",
            "epoch:76,batch: 300, train_loss: 0.26481989324092864, valid_loss: 0.26088746224084625\n",
            "epoch:77,batch: 100, train_loss: 0.2689359712600708, valid_loss: 0.2664488747553981\n",
            "epoch:77,batch: 200, train_loss: 0.27260323368012906, valid_loss: 0.2566775068154801\n",
            "epoch:77,batch: 300, train_loss: 0.275460095256567, valid_loss: 0.26368089457568916\n",
            "epoch:78,batch: 100, train_loss: 0.27957691326737405, valid_loss: 0.28275076688631723\n",
            "epoch:78,batch: 200, train_loss: 0.25989996440708635, valid_loss: 0.3035633149354354\n",
            "epoch:78,batch: 300, train_loss: 0.2654293362051249, valid_loss: 0.2560112372688625\n",
            "epoch:79,batch: 100, train_loss: 0.2766825572401285, valid_loss: 0.2665826636164085\n",
            "epoch:79,batch: 200, train_loss: 0.27497414372861384, valid_loss: 0.26796133589485416\n",
            "epoch:79,batch: 300, train_loss: 0.2664075829088688, valid_loss: 0.2881800796350707\n",
            "epoch:80,batch: 100, train_loss: 0.27665505729615686, valid_loss: 0.25951429229715595\n",
            "epoch:80,batch: 200, train_loss: 0.2657160784304142, valid_loss: 0.2530373670970616\n",
            "epoch:80,batch: 300, train_loss: 0.27614646062254905, valid_loss: 0.2631755856716115\n",
            "epoch:81,batch: 100, train_loss: 0.27432471632957456, valid_loss: 0.2870617691913377\n",
            "epoch:81,batch: 200, train_loss: 0.27209967002272606, valid_loss: 0.25812295435563376\n",
            "epoch:81,batch: 300, train_loss: 0.2702928976714611, valid_loss: 0.26936769728427346\n",
            "epoch:82,batch: 100, train_loss: 0.2686178384721279, valid_loss: 0.28826017370042595\n",
            "epoch:82,batch: 200, train_loss: 0.2637773604691029, valid_loss: 0.2723270001942697\n",
            "epoch:82,batch: 300, train_loss: 0.2694598540663719, valid_loss: 0.2792645768140969\n",
            "epoch:83,batch: 100, train_loss: 0.2760876290500164, valid_loss: 0.2703028386053832\n",
            "epoch:83,batch: 200, train_loss: 0.262188626229763, valid_loss: 0.2685462830831175\n",
            "epoch:83,batch: 300, train_loss: 0.264324269965291, valid_loss: 0.2640141145042751\n",
            "epoch:84,batch: 100, train_loss: 0.2671320136636496, valid_loss: 0.26115140691399574\n",
            "epoch:84,batch: 200, train_loss: 0.26385736614465716, valid_loss: 0.25914706273571303\n",
            "epoch:84,batch: 300, train_loss: 0.2690555652976036, valid_loss: 0.26684067066272965\n",
            "epoch:85,batch: 100, train_loss: 0.27743652179837225, valid_loss: 0.2632735101911037\n",
            "epoch:85,batch: 200, train_loss: 0.2710680349171162, valid_loss: 0.26300180590023164\n",
            "epoch:85,batch: 300, train_loss: 0.26041744105517867, valid_loss: 0.291773298026427\n",
            "epoch:86,batch: 100, train_loss: 0.2839816003292799, valid_loss: 0.26884541984485544\n",
            "epoch:86,batch: 200, train_loss: 0.26024733647704124, valid_loss: 0.2618064481927001\n",
            "epoch:86,batch: 300, train_loss: 0.26631618149578573, valid_loss: 0.28726921530197497\n",
            "epoch:87,batch: 100, train_loss: 0.2760991625487804, valid_loss: 0.26657660694225976\n",
            "epoch:87,batch: 200, train_loss: 0.26119790114462377, valid_loss: 0.29069267780236574\n",
            "epoch:87,batch: 300, train_loss: 0.2656603238731623, valid_loss: 0.2532256104699943\n",
            "epoch:88,batch: 100, train_loss: 0.26479928582906725, valid_loss: 0.2632107690948507\n",
            "epoch:88,batch: 200, train_loss: 0.25496028766036033, valid_loss: 0.3168120027884193\n",
            "epoch:88,batch: 300, train_loss: 0.2688587246835232, valid_loss: 0.2747248382024143\n",
            "epoch:89,batch: 100, train_loss: 0.2648013372719288, valid_loss: 0.2547325682218956\n",
            "epoch:89,batch: 200, train_loss: 0.26276811689138413, valid_loss: 0.2549644017835026\n",
            "epoch:89,batch: 300, train_loss: 0.26985527746379373, valid_loss: 0.2847681921785292\n",
            "epoch:90,batch: 100, train_loss: 0.2643614923208952, valid_loss: 0.2564037090734295\n",
            "epoch:90,batch: 200, train_loss: 0.26448680490255355, valid_loss: 0.2731355164685975\n",
            "epoch:90,batch: 300, train_loss: 0.26679310977458953, valid_loss: 0.28659885830205417\n",
            "epoch:91,batch: 100, train_loss: 0.2713221122324467, valid_loss: 0.28039514273405075\n",
            "epoch:91,batch: 200, train_loss: 0.2614610905200243, valid_loss: 0.2996409258440785\n",
            "epoch:91,batch: 300, train_loss: 0.2552152366936207, valid_loss: 0.2521209115891353\n",
            "epoch:92,batch: 100, train_loss: 0.27958248659968377, valid_loss: 0.28213750085105066\n",
            "epoch:92,batch: 200, train_loss: 0.26055791981518267, valid_loss: 0.27180182148257026\n",
            "epoch:92,batch: 300, train_loss: 0.26148850545287133, valid_loss: 0.259243531152606\n",
            "epoch:93,batch: 100, train_loss: 0.2654767242819071, valid_loss: 0.25663918483516446\n",
            "epoch:93,batch: 200, train_loss: 0.2639935520291328, valid_loss: 0.264185788028914\n",
            "epoch:93,batch: 300, train_loss: 0.2691620488464832, valid_loss: 0.26654396360011207\n",
            "epoch:94,batch: 100, train_loss: 0.2672501312196255, valid_loss: 0.27333752106389275\n",
            "epoch:94,batch: 200, train_loss: 0.25919781215488913, valid_loss: 0.2564908254729665\n",
            "epoch:94,batch: 300, train_loss: 0.2726045400649309, valid_loss: 0.2894248978599258\n",
            "epoch:95,batch: 100, train_loss: 0.2774443054199219, valid_loss: 0.2987838461995125\n",
            "epoch:95,batch: 200, train_loss: 0.26386424511671064, valid_loss: 0.27045290949551953\n",
            "epoch:95,batch: 300, train_loss: 0.260524135902524, valid_loss: 0.251703503906079\n",
            "epoch:96,batch: 100, train_loss: 0.26270739145576955, valid_loss: 0.2669444351416567\n",
            "epoch:96,batch: 200, train_loss: 0.2661456637084484, valid_loss: 0.2719574672696383\n",
            "epoch:96,batch: 300, train_loss: 0.27309651523828504, valid_loss: 0.28300014656523\n",
            "epoch:97,batch: 100, train_loss: 0.25152948662638663, valid_loss: 0.2546053438892831\n",
            "epoch:97,batch: 200, train_loss: 0.27028144970536233, valid_loss: 0.2794057633727789\n",
            "epoch:97,batch: 300, train_loss: 0.26315344974398613, valid_loss: 0.25271819118896255\n",
            "epoch:98,batch: 100, train_loss: 0.254650898873806, valid_loss: 0.2510017524270908\n",
            "epoch:98,batch: 200, train_loss: 0.26527892380952833, valid_loss: 0.3001106912675111\n",
            "epoch:98,batch: 300, train_loss: 0.26330103002488614, valid_loss: 0.25286032146085863\n",
            "epoch:99,batch: 100, train_loss: 0.26175221629440787, valid_loss: 0.2663031494163949\n",
            "epoch:99,batch: 200, train_loss: 0.2627827721089125, valid_loss: 0.2870955922357414\n",
            "epoch:99,batch: 300, train_loss: 0.2699634100496769, valid_loss: 0.28062542333551077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.array(valid_losses)[:,0],np.array(valid_losses)[:,1])\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"valid loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "c4pMer0t_ZcG",
        "outputId": "5900d904-f16f-4144-c274-42f817d43df0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'valid loss')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.accuracy(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or5Y-eFEJff1",
        "outputId": "d4e72fe2-ddec-4f61-ac13-7620ec83d5b1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.890038809831824"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.predict(\"hello there\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_9kRgVB1XACk",
        "outputId": "45cf9435-08b1-4aa8-9d19-8bb858d58a70"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'offensive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QllGxxs8XFps"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}